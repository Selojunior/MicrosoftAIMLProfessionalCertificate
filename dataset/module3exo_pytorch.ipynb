{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Using device: cpu\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1763993144626
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 1. DATA PREPROCESSING PIPELINE (NORMALIZATION)\n",
        "# ============================================================\n",
        "# Every ML project MUST normalize pixel values.\n",
        "# CIFAR-10 images are originally between 0–255.\n",
        "# ToTensor() → converts them to [0,1]\n",
        "# Normalize(mean, std) → standardizes each RGB channel.\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),                       # Convert to PyTorch tensors\n",
        "    transforms.Normalize(\n",
        "        (0.5, 0.5, 0.5),                         # Normalize R,G,B to mean 0.5\n",
        "        (0.5, 0.5, 0.5)                          # Normalize with std 0.5\n",
        "    )\n",
        "])"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1763993419674
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #============================================================\n",
        "# 2. LOAD CIFAR-10 DATASET (TRAIN + TEST)\n",
        "# ============================================================\n",
        "# CIFAR-10 automatically downloads the dataset if missing.\n",
        "\n",
        "full_trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=True,                                   # 50,000 training images\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=False,                                  # 10,000 test images\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 170M/170M [00:05<00:00, 31.0MB/s] \n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1763993469101
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 3. TRAIN/VALIDATION SPLIT\n",
        "# ============================================================\n",
        "# We split the 50,000 training images:\n",
        "# 90% (45,000) → train\n",
        "# 10% (5,000)  → validation\n",
        "# Validation is CRITICAL for monitoring overfitting.\n",
        "\n",
        "train_size = int(0.9 * len(full_trainset))\n",
        "val_size   = len(full_trainset) - train_size\n",
        "\n",
        "trainset, valset = random_split(full_trainset, [train_size, val_size])\n",
        "\n",
        "\n",
        "# Create DataLoaders (batches the data during training)\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "valloader   = DataLoader(valset,   batch_size=64, shuffle=False, num_workers=2)\n",
        "testloader  = DataLoader(testset,  batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "# Class names for CIFAR-10\n",
        "classes = ['plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck']\n"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1763993521702
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 4. DEFINE THE CNN MODEL \n",
        "# ============================================================\n",
        "# This CNN has:\n",
        "# - 2 convolutional blocks\n",
        "# - 2 maxpool layers\n",
        "# - 3 fully connected layers\n",
        "# - Outputs 10 logits (one per class)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # First conv layer: input=RGB(3), output=6 filters, kernel=5x5\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "\n",
        "        # Max pooling layer: halves image size\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Second conv layer: 6 → 16 channels, kernel=5x5\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "\n",
        "        # After conv+pool, the output size is 16 * 5 * 5\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)   # Fully connected\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)            # Final layer: 10 logits\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Conv1 → ReLU → Pool\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        # Conv2 → ReLU → Pool\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "\n",
        "        # Flatten feature maps into a vector\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "\n",
        "        # FC layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "\n",
        "        # Output layer (NO softmax — CrossEntropyLoss applies it internally)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = Net().to(device)\n"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1763993605814
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 5. LOSS FUNCTION + OPTIMIZER  (\"COMPILE\" IN TF)\n",
        "# ============================================================\n",
        "criterion = nn.CrossEntropyLoss()                   # multi-class classification loss\n",
        "optimizer = optim.SGD(net.parameters(),             # Stochastic Gradient Descent\n",
        "                      lr=0.001,                     # learning rate\n",
        "                      momentum=0.9)                 # momentum improves convergence\n"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1763993668938
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 6. TRAINING LOOP (THE MODEL LEARNS HERE)\n",
        "# ============================================================\n",
        "# Each epoch goes through all training batches once.\n",
        "# We compute training loss but DO NOT touch validation here.\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    net.train()                                     # Enable dropout/batchnorm if used\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(trainloader):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()                       # Clear previous gradients\n",
        "        outputs = net(inputs)                       # Forward pass\n",
        "        loss = criterion(outputs, labels)           # Compute loss\n",
        "        loss.backward()                              # Backpropagation\n",
        "        optimizer.step()                             # Update weights\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = running_loss / len(trainloader)\n",
        "\n",
        "\n",
        "    # ============================================================\n",
        "    # 7. VALIDATION (EVALUATE ON valset EACH EPOCH)\n",
        "    # ============================================================\n",
        "    net.eval()                                       # Disable dropout/batchnorm\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():                            # No gradients needed\n",
        "        for inputs, labels in valloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)     # Class with highest logit\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(valloader)\n",
        "    val_accuracy = 100 * correct / total\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
        "          f\"Train Loss: {avg_train_loss:.4f} | \"\n",
        "          f\"Val Loss: {avg_val_loss:.4f} | \"\n",
        "          f\"Val Acc: {val_accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "print(\"\\nTraining completed successfully!\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/10 | Train Loss: 2.2972 | Val Loss: 2.2836 | Val Acc: 19.72%\nEpoch 2/10 | Train Loss: 2.1637 | Val Loss: 2.0206 | Val Acc: 27.24%\nEpoch 3/10 | Train Loss: 1.9210 | Val Loss: 1.8279 | Val Acc: 33.74%\nEpoch 4/10 | Train Loss: 1.7554 | Val Loss: 1.6879 | Val Acc: 38.46%\nEpoch 5/10 | Train Loss: 1.6542 | Val Loss: 1.6289 | Val Acc: 40.30%\nEpoch 6/10 | Train Loss: 1.5727 | Val Loss: 1.5415 | Val Acc: 43.74%\nEpoch 7/10 | Train Loss: 1.4932 | Val Loss: 1.4631 | Val Acc: 46.30%\nEpoch 8/10 | Train Loss: 1.4277 | Val Loss: 1.4002 | Val Acc: 49.20%\nEpoch 9/10 | Train Loss: 1.3764 | Val Loss: 1.3886 | Val Acc: 49.76%\nEpoch 10/10 | Train Loss: 1.3334 | Val Loss: 1.3473 | Val Acc: 51.18%\n\nTraining completed successfully!\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1763993833801
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 8. FINAL TEST ACCURACY ON 10,000 UNSEEN IMAGES\n",
        "# ============================================================\n",
        "net.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_accuracy = 100 * correct / total\n",
        "print(f\"\\nFinal Accuracy on 10,000 test images: {test_accuracy:.2f}%\\n\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nFinal Accuracy on 10,000 test images: 51.71%\n\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1763993936922
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 9. PREDICT ON YOUR OWN IMAGE (e.g., car.jpg)\n",
        "# ============================================================\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "# Load your own image (replace 'car.jpg' with your filename)\n",
        "img_path = \"car.jpg\"\n",
        "img = Image.open(img_path)\n",
        "\n",
        "# --- IMPORTANT ---\n",
        "# CIFAR-10 images are 32x32, so resize your image\n",
        "img = img.resize((32, 32))\n",
        "\n",
        "# Convert to tensor AND apply same normalization as training\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        (0.5, 0.5, 0.5),   # SAME mean used in training\n",
        "        (0.5, 0.5, 0.5)    # SAME std used in training\n",
        "    )\n",
        "])\n",
        "\n",
        "# Apply transforms\n",
        "img_tensor = transform(img)\n",
        "\n",
        "# Add batch dimension → shape becomes (1, 3, 32, 32)\n",
        "img_tensor = img_tensor.unsqueeze(0).to(device)\n",
        "\n",
        "# Predict\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = net(img_tensor)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print(\"\\nPrediction for your image:\", img_path)\n",
        "print(\"Predicted class:\", classes[predicted.item()])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nPrediction for your image: car.jpg\nPredicted class: car\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1763994082662
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 10. SAVE THE TRAINED MODEL\n",
        "# ============================================================\n",
        "torch.save(net.state_dict(), \"cifar10_cnn_pytorch.pth\")\n",
        "print(\"\\nModel saved as cifar10_cnn_pytorch.pth\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nModel saved as cifar10_cnn_pytorch.pth\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1763994115214
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.10 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}